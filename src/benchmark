#!/bin/bash

if [ $# = 2 ]; then
    TAG=${1}
    RPS=${2}
    if [[ -z $CONFIG ]]; then
        echo "Benchmark must be run from batch_run as of now, depends on \$CONFIG" >&2
        exit
    fi
else
    echo "Run tag and RPS are required arguments" >&2
    exit
fi

LOGDIR="$OUTDIR/logs"
STATSDIR="$OUTDIR/stats"
ERIS_DIR="$OUTDIR/eris"
LOGFILE="$LOGDIR/$RPS"
STATSFILE="$STATSDIR/$RPS"
ERIS_LOG="$ERIS_DIR/$RPS"

mkdir -p $LOGDIR $STATSDIR $ERIS_DIR
cp "$CONFIG" "$OUTDIR/conf.env"

export CONNECTIONS=$(($CPW * $CLIENT_WORKERS))
export N_ROWS=$(($RUNTIME / $STATS_INTERVAL))

if [[ -f "$OUTDIR/params.txt" ]]; then
    echo "$RPS" >> $OUTDIR/params.txt
else
    printf "$(date)\nTag: $TAG\n" > "$OUTDIR/params.txt"
    printf "RPS:\n$RPS\n" >> "$OUTDIR/params.txt"
fi

_cleanup() {
    docker rm -f dc-warmup dc-client &> /dev/null

    docker logs stress > "${LOGFILE}.stress"
    docker rm -f stress &> /dev/null

    kill "$STATS_ID"
    echo "Waiting for stats cleanup ..."
    wait $STATS_ID
    docker rm -f dc-server &> /dev/null

    # Format OSR file
    tr ' ' ',' < "${LOGFILE}.osr" | sed 's/,$//' | sponge "${LOGFILE}.osr"

    # Parse eris output
    kill "$ERIS_ID"
    grep "set container stress cpu quota" "$ERIS_LOG.log" | sed 's/ERROR.*//' | awk '$2 = $2","' | awk '{print $1,$2,$9}' > "$ERIS_LOG.quota"
    # grep "set container stress cpu share" "$ERIS_LOG.log" > "$ERIS_LOG.share"
    # grep "set container stress llc" "$ERIS_LOG.log" > "$ERIS_LOG.llc"

    echo "Cleanup has been completed"
    [ ! -z $(jobs -p) ] && kill -9 $(jobs -p)

    # TODO: actually verify
    echo "__________________________"
    echo "Verifying output integrity"
    echo "--------------------------"
    echo "$(wc -l ${LOGFILE}.lat) = $(wc -l ${LOGFILE}.osr) = $(wc -l ${LOGFILE}.rps)"
    echo "Collected $(jq length $STATSFILE.json) stats API responses" 
    echo "$(wc -l $STATSFILE.time) = $(wc -l $STATSFILE.rapl)"
}
trap _cleanup EXIT

init_logs() {
    echo "timestamp, timeDiff, rps, requests, gets, sets, hits, misses, avg_lat, 90th, 95th, 99th, std, min, max, avgGetSize" > "${LOGFILE}.lat" 

    echo -n "timestamp " > "${LOGFILE}.osr"
    for i in $(seq $CLIENT_WORKERS); do
        if [[ $i = $CLIENT_WORKERS ]]; then
            echo "osr$i" >> "${LOGFILE}.osr"
        else
            echo -n "osr$i " >> "${LOGFILE}.osr"
        fi
    done

    echo "rps" > "${LOGFILE}.rps"
}

run_dynamic_step() {
    local rps="$1"
    echo -n "Benchmarking $rps rps, started at $(date +%T), dc-client: "
    docker run -d \
        --net dc \
        --name dc-client \
        --cpuset-cpus=1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35 \
        --cpuset-mems=1 \
        -v $BASEDIR/src/entrypoints/dynamic.sh:/entrypoint.sh \
        --env-file "$CONFIG" -e CONNECTIONS \
        -e STEP_TIME -e STEP_INTERVAL -e N_ROWS \
        jonassa/data-caching:client-ts $rps
}

process_client_logs() {
    local rps="$1"
    # docker logs -t dc-client | grep -v -e "starting receive" -e "Creating worker" -e "num_worker" > "${LOGFILE}_${rps}.txt"
    # docker logs -t dc-client > "${LOGFILE}_${rps}.txt" 2> /dev/null
    # TODO: rps not unique, might as well use a single .txt file
    # docker logs -t dc-client > "${LOGFILE}_${rps}.txt"
    docker logs -t dc-client > "${LOGFILE}.txt" 2> /dev/null

    sed -n '/timeDiff/{n;p}' "${LOGFILE}.txt" | awk '$1 = $1","' | sed 1d >> "${LOGFILE}.lat"
    sed -n '/Outstanding/{n;p}' "${LOGFILE}.txt" | sed 1d >> "${LOGFILE}.osr"

    step_n_rows=$(sed -n '/timeDiff/{n;p}' "${LOGFILE}.txt" | sed 1d | wc -l)
    for i in $(seq $step_n_rows); do
        echo $rps >> "$LOGFILE.rps"
    done

    docker rm -f dc-client &> /dev/null
}

printf "\n============================================================================================\n"
printf "Benchmarking memcached with $RPS attempted RPS, for $(expr $RUNTIME / 60) minutes, reporting every $STATS_INTERVAL seconds"
printf "\n============================================================================================\n\n"

# alias run_server='docker run --cpuset-cpus=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34 --cpuset-mems=0'
# alias run_client='docker run --cpuset-cpus=1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35 --cpuset-mems=1'

docker rm -f dc-server dc-client dc-warmup stress &> /dev/null

# Start server
export SERVER_ID=$(docker run -d \
    --net dc \
    --name dc-server \
    --cpuset-cpus=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34 \
    --cpuset-mems=0 \
    cloudsuite/data-caching:server \
        -t $SERVER_WORKERS -m $SERVER_MEMORY -n $SERVER_MIN)
echo "Running dc-server: $SERVER_ID"

# Warm up server
echo -n "Running dc-warmup: "
docker run -d --rm \
    --net dc \
    --name dc-warmup \
    --cpuset-cpus=1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35 \
    --cpuset-mems=1 \
    -v $BASEDIR/src/entrypoints/warmup.sh:/entrypoint.sh \
    --env-file "$CONFIG" -e CONNECTIONS \
    jonassa/data-caching:client-ts

echo "Warming up the server ..."
docker container wait dc-warmup

# Start eris
if [ "$USE_ERIS" = 1 ]; then
    cd /opt/platform-resource-manager/eris

    # ts "%F %R:%.S%z"
    export TZ='UTC'
    numactl --cpunodebind=0 --membind=0 \
        python3 eris.py -v --collect-metrics --record --detect --control workload.json &> "$ERIS_LOG.log" &
    ERIS_ID=$!
    echo "Running eris: $ERIS_ID"
    cd -
fi

# if [ "$USE_ERIS" = 1 ]; then
#     ERIS_ID=$(run_eris)
#     echo "Running eris: $ERIS_ID"
# fi

# Run stress-ng
if [ "$USE_STRESS" = 1 ]; then
    export STRESS_ID=$(docker run -d --rm \
        --name stress \
        --cpuset-cpus=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34 \
        --cpuset-mems=0 \
        polinux/stress-ng \
            --metrics-brief --timeout 0 \
            $STRESS_PARAMS)
    echo -n "Running stress-ng: $STRESS_ID"
fi

# --vm 9 \
# --vm-bytes 4g \
# --cpu 18 \
# --cpu-load 50 \

# Run benchmark
if [ "$DYNAMIC_LOAD" = 1 ]; then

    N_STEPS=5
    export STEP_TIME=$(($RUNTIME / $N_STEPS))
    export STEP_INTERVAL=$(($STATS_INTERVAL / $N_STEPS))

    RPS_LOW=$(($RPS / 4)) # 25 %
    RPS_MID=$(($RPS / 2)) # 50 %
    RPS_HIGH=$RPS         # 100 %

    # Five-step benchmark: 25 -> 50 -> 100 -> 50 -> 25
    RPS_STEPS="$RPS_LOW $RPS_MID $RPS_HIGH $RPS_MID $RPS_LOW"

    $BASEDIR/src/stats "$STATSFILE" & STATS_ID=$!
    echo "Stats collection started at $(date +%T): $STATS_ID"

    init_logs

    # Dynamic steps
    for rps in $RPS_STEPS; do
        run_dynamic_step "$rps"
        echo "Benchmarking the server ..."
        docker container wait dc-client
        process_client_logs "$rps"
    done


else
    echo "Only dynamic loads are supported atm" >&2
    exit
    # docker run -d \
    #     --net dc \
    #     --name dc-client \
    #     --cpuset-cpus=1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35 \
    #     --cpuset-mems=1 \
    #     -v $BASEDIR/src/entrypoints/entrypoint.sh:/entrypoint.sh \
    #     --env-file "$CONFIG" -e CONNECTIONS \
    #     jonassa/data-caching:client-ts $RPS &> /dev/null

fi

# echo "Benchmarking the server ..."
# docker container wait dc-client

echo "--------------------------------"
echo "Benchmark at $RPS rps complete"
echo "--------------------------------"

